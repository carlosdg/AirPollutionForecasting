\documentclass[12pt]{article}

\usepackage{csquotes}
\usepackage[spanish]{babel}
\usepackage[hidelinks]{hyperref} % So the Table of Contents to has links to the sections
\usepackage{xcolor} % For the hyperref link colors
\usepackage[backend=biber, style=numeric, citestyle=numeric]{biblatex}
\usepackage{graphicx} % To embed images
\usepackage{cleveref} % To reference with cref and see the name of the object

\hypersetup{colorlinks = true, allcolors={blue!80!black}}
\addbibresource{Resources/Bibliography/bibliography.bib} % Imports bibliography file
\graphicspath{ {Resources/Images/} } % Sets the path to look for images 
\title{Base de datos y Hadoop}
\author{Carlos Domínguez García (alu0100966589@ull.edu.es)}
\date{17 de febrero de 2019}

\begin{document}

  \maketitle
  \pagebreak
  
  \tableofcontents
  \pagebreak

  \section{Introducción}
    Sin bases de datos la única manera de almacenar datos de manera persistente es interactuando con el sistema de almacenamiento. Esto que implica que las aplicaciones, para poder usar los datos tengan que implementar operaciones CRUD (Create, Read, Update, Delete) sobre el sistema de almacenamiento. Por ejemplo, es común interactuar a través de un sistema de archivos, en este caso las aplicaciones tienen que encargarse de abrir o crear los archivos, entender el formato del contenido, actualizar el contenido escribiendo en el fichero y cerrarlo.

    Esta añadida complejidad de las aplicaciones abre la posibilidad a una mayor cantidad errores en su código. Pero también, debido la falta de una manera estándar de acceder a los datos, cada aplicación podría implementar el manejo de los datos de manera distinta provocando redundancia si aplicaciones que necesitaban los mismos datos los almacenaban en distintos ficheros, inconsistencia si estos datos duplicados unos se actualizaban y otros no, más problemas de inconsistencia si no se garantiza que las transacciones sean atómicas, es decir, o tienen lugar todas las operaciones asociadas a la transacción en el orden previsto o no tiene lugar ninguna, etc. \cite{MariaDB_EarlyDatabaseModels}

    Para resolver esta situación surgieron los sistemas gestores de bases de datos. Este tipo de sistema se sitúa entre los usuarios y el sistema de almacenamiento, proporcionando una estructura lógica de los datos y una interfaz que permite a los usuarios referirse a los datos según la estructura lógica. De esta manera pueden usar una interfaz con un alto nivel de abstracción y no se tienen que preocupar de los problemas relacionados con interactuar directamente con los ficheros ya que el sistema también se encarga de ello.
    
    El primer modelo de datos fue el modelo jerárquico \cite{MariaDB_HierarchicalDatabaseModel}. Aquí los datos se disponen en una colección de valores llamados registros, que están relacionados por enlaces de nodos padres a hijos simulando una estructura de árbol invertido. Sin embargo, este modelo lleva consigo algunos inconvenientes como que no es bueno para representar relaciones muchos a muchos. Por ejemplo, alumnos inscritos a varias clases y clases con varios alumnos como se puede observar en \cref{fig:HierarchicalModelManyToMany}. Además, añadir nuevas relaciones puede implicar que se tenga que cambiar toda la estructura y, para referirse a un dato, los usuarios han de conocer bien la estructura para saber qué enlaces recorrer. Y, en caso de necesitar buscar datos en los nodos hojas, tener que hacerlo por todo el árbol en el peor caso.

    \begin{figure}[h]
      \includegraphics[width=\textwidth]{HierarchicalModelManyToMany.png}
      \centering
      \caption[Representación de una relación muchos a muchos en el modelo jerárquico]{Representación de la relación muchos a muchos en el modelo jerárquico, en concreto se puede observar que para cada alumno de primer año se han de repetir los registros de las asignaturas}
      \label{fig:HierarchicalModelManyToMany}
    \end{figure}

  \section{Base de datos relacionales}
    La inflexibilidad de los modelos de base de datos del momento llevó a Edgar F. Codd a publicar en 1970 \textit{Relational Model of Data Large Shared Data Banks} \cite{Codd_RelationalModelofDataLargeSharedDataBanks}. Aquí introdujo el modelo relacional de datos donde los datos se representan como relaciones de $n$ dominios $R \subseteq S_1 \times S_2 \times...\times S_n$. Actualmente se usa el término tabla como una conveniente representación de las relaciones porque, aunque las relaciones no permitan valores duplicados y las t-uplas no tengan un orden, en las implementaciones del modelo relacional en base de datos sí se pueden tener t-uplas duplicadas como resultados de consultas y sí hay un orden porque tienen que ser guardadas físicamente.

    % https://en.wikipedia.org/wiki/Table_(database)#Tables_versus_relations

    En las bases de datos relacionales se pueden restringir los valores de los atributos (columnas) o incluso pueden haber restricciones a nivel de tabla, todo con el objetivo de mejorar la integridad de los datos, es decir, proteger los datos para que lo que esté almacenado sea consistente y tenga sentido para la persona u organización que lleva la base de datos \cite{Stackoverflow_WhatAreDatabaseConstraints}. Un ejemplo de restricción es la clave principal, que es un conjunto de atributos que se han de usar para identificar inequívocamente a las filas de una tabla. Otra posible restricción es la clave foránea que es una referencia a la clave principal de otra tabla. Es gracias a esto que con el modelo relacional se pueden relacionar t-uplas entre tablas sin necesidad de usar punteros como hacían modelos anteriores. 
    
    Así es como este modelo permite una representación de los datos más flexibles que los anteriores. En palabras de Codd: ``It provides a means of describing data with its natural structure only--that is, without superimposing any additional structure for machine representation purposes.'' \cite{Codd_RelationalModelofDataLargeSharedDataBanks}.


    % TODO:
    % Relational model, ACID, normalization... scaling (vertical, horizontal for read and writing)

    % - https://aws.amazon.com/es/nosql/
  
  \section{Base de datos distribuidas}
    % TODO:
    % Scalability (horizontal, vertical), CAP, problems with ACID. big data... and thats why nosql

    % - https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed

  \section{Base de datos NoSQL (Not only SQL)}
    % TODO:
    % Mongo, Cassandra, HBase(?). Where each fits in CAP

    % - https://www.3pillarglobal.com/insights/short-history-databases-rdbms-nosql-beyond
    % - https://stackoverflow.com/questions/48240702/mongo-and-cassandra-in-context-of-cap
    % - https://www.scnsoft.com/blog/cassandra-vs-hadoop
    % - https://www.dataversity.net/review-pros-cons-different-databases-relational-versus-non-relational/
    
    \section{Hadoop}
    % TODO:
    % nosql vs hadoop (NoSQL use cases often entail end user interactivity, like in web applications, but more broadly they are about reading and writing data very quickly. Hadoop, on the other hand, is about large-scale processing of data. To process large volumes of data, you want to do the work in parallel, and typically across many servers. -- https://mapr.com/blog/hadoop-vs-nosql-whiteboard-walkthrough/)

    % - https://www.dataversity.net/comparative-roundup-artificial-intelligence-vs-machine-learning-vs-deep-learning-2/

    \subsection{HDFS}
    \subsection{MapReduce}
    \subsection{YARN}

  \section{Spark}
    % TODO:
    % Batch processing vs Stream processing

    % - https://medium.com/stream-processing/right-tool-for-the-job-why-you-shouldnt-do-stream-processing-with-mapreduce-539e180565e6
    % - https://medium.com/@gowthamy/big-data-battle-batch-processing-vs-stream-processing-5d94600d8103
    % - https://www.quora.com/What-is-stream-processing-in-big-data-and-what-does-it-do
    % - https://opencredo.com/blogs/data-analytics-using-cassandra-and-spark/
  
  \printbibliography
  
\end{document}